{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pip Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\anaconda3\\envs\\AirScope\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import langchain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pdf loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFLoader:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "\n",
    "    def extract_text(self):\n",
    "        doc = fitz.open(self.pdf_path)\n",
    "        text = \"\"\n",
    "\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai_api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not set\")\n",
    "        \n",
    "    # split into chunks by tokens\n",
    "    def chunk_text_by_tokens(self, text, chunk_size, encoding_name=\"cl100k_base\"):\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        tokens = encoding.encode(text)\n",
    "        return [encoding.decode(tokens[i:i + chunk_size]) for i in range(0, len(tokens), chunk_size)]\n",
    "\n",
    "    # generate embeddings for each chunk and return list of embeddings\n",
    "    def generate_embeddings(self, chunks):\n",
    "        embeddings = []\n",
    "        for chunk in chunks:\n",
    "            response = openai.embeddings.create(\n",
    "                input=chunk,\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )\n",
    "            embeddings.append(response.data[0].embedding)\n",
    "        return embeddings\n",
    "    \n",
    "    # split text into chunks and generate embeddings\n",
    "    def process_text(self, text, chunk_size=1000):\n",
    "        if not isinstance(text, str) or len(text) == 0:\n",
    "            raise ValueError(\"Input text must be a non-empty string\")\n",
    "        chunks = self.chunk_text_by_tokens(text, chunk_size)\n",
    "        embeddings = self.generate_embeddings(chunks)\n",
    "        return chunks, embeddings\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generator = EmbeddingGenerator()\n",
    "#     chunks, embeddings = generator.process_text(text, chunk_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeStore:\n",
    "\n",
    "    def __init__(self, environmeent=\"us-east-1\"):\n",
    "        pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        if not pinecone_api_key:\n",
    "            raise ValueError(\"PINECONE_API_KEY not set\")\n",
    "        \n",
    "        # pinecone instance\n",
    "        self.pc = Pinecone(ap_key=pinecone_api_key)\n",
    "        self.index_name = \"text-analyzer\"\n",
    "\n",
    "        if self.index_name not in self.pc.list_indexes().names():\n",
    "            self.pc.create_index(\n",
    "                name=self.index_name,\n",
    "                dimension=1536,\n",
    "                metric='cosine',\n",
    "                spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
    "    )\n",
    "    \n",
    "    def save_vectors(self, vectors, metadata, chunks):\n",
    "        index = self.pc.Index(self.index_name)\n",
    "\n",
    "        # save each embedding with unique metadata\n",
    "        for i, vector in enumerate(vectors):\n",
    "            vector_id = f\"{metadata['id']}_chunk_{i}\" # uniqe id\n",
    "            chunk_metadata = {\n",
    "                \"id\": vector_id,\n",
    "                \"source\" : metadata[\"source\"],\n",
    "                \"chunk\" : i,\n",
    "                \"text\": chunks[i]\n",
    "            }\n",
    "\n",
    "            index.upsert(vectors=[(vector_id, vector, chunk_metadata)])\n",
    "\n",
    "    def delete(self):\n",
    "        index = self.pc.Index(self.index_name)\n",
    "        index.delete(delete_all=True)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     vector_store = PineconeStore()\n",
    "#     vector_store.save_vectors(embeddings, {\"id\": \"doc_1\", \"source\": \"example.pdf\"}, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PineconeRetriever:\n",
    "    def __init__(self, pinecone_api_key, openai_api_key):\n",
    "\n",
    "        # pinecone connection\n",
    "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
    "        self.index_name = \"text-analyzer\"\n",
    "        self.index = self.pc.Index(self.index_name)\n",
    "\n",
    "        # openAi model and embeddings\n",
    "        self.embedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "        self.llm = OpenAI(temperature=0, api_key=openai_api_key)\n",
    "\n",
    "        # create the Pinecone vector store\n",
    "        self.vector_store = PineconeVectorStore(index=self.index, embedding=self.embedding_model, text_key=\"text\")\n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "\n",
    "        # create the RetrievalQA chain\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, chain_type=\"stuff\", retriever=self.retriever)\n",
    "\n",
    "    def query(self, query_text):\n",
    "        # execute the QA chain with the input query\n",
    "        response = self.qa_chain.invoke({\"query\": query_text})\n",
    "        return response['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    folder_path = \"./pdfs\"\n",
    "    generator = EmbeddingGenerator()\n",
    "    vector_store = PineconeStore()\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(folder_path, file)\n",
    "                print(f\"Processing: {file}\")\n",
    "\n",
    "                try:\n",
    "                    loader = PDFLoader(pdf_path)\n",
    "                    text = loader.extract_text()\n",
    "\n",
    "                    chunks, embeddings = generator.process_text(text, chunk_size=800)\n",
    "                    metadata = {\"id\": file.split(\".\")[0], \"source\": file}\n",
    "                    vector_store.save_vectors(embeddings, metadata, chunks)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "    pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    retriever = PineconeRetriever(pinecone_api_key=pinecone_api_key, openai_api_key=openai_api_key)\n",
    "\n",
    "\n",
    "    # query = (\"You are a genius on everything related to civil engineering and conrete canoe.\"\n",
    "    #          \"You only answer questions based on this topic. Tell me about the Project Proposals.\"\n",
    "    #           )\n",
    "\n",
    "    # result = retriever.query(query)\n",
    "    # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unfortunately, I do not have access to the specific names of the canoes proposed by NYU in their Concrete Canoe Project Proposals. However, some of the key components of their proposals included a hull design, structural analysis, mix design, construction process, project schedule, and sustainability plan.\n"
     ]
    }
   ],
   "source": [
    "query = (\"Tell me about the Concrete Canoe Project Proposals of NYU, what were the names of some of their canoes?\"\n",
    "              )\n",
    "\n",
    "result = retriever.query(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AirScope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
